{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "import MetaTrader5 as mt5\n",
    "import calendar\n",
    "from datetime import datetime, date\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "\n",
    "INPUT_SYMBOL = 'EURUSD'\n",
    "\n",
    "IMAGE_LENGTH_M15 = 24\n",
    "IMAGE_LENGTH_H1 = 24\n",
    "IMAGE_LENGTH_H4 = 12\n",
    "IMAGE_LENGTH_M5 = 12\n",
    "IMAGE_LENGTH_D1 = 10\n",
    "\n",
    "DAY = 2 * np.pi / (24*60*60)\n",
    "WEEK = DAY / 7\n",
    "YEAR = DAY / (365.2425)\n",
    "\n",
    "THRESOLD_DIFF = 2\n",
    "TARGET = 3\n",
    "\n",
    "DAY_HISTORY_TO_PROCESS = 100\n",
    "\n",
    "F_SINGLE_MEDIUM = True\n",
    "F_VOLUME = True\n",
    "F_REPEAT = 1\n",
    "F_TIME = False\n",
    "F_LABEL_TIMEFRAME = 'H1'\n",
    "F_LABEL_PERIOD = 120\n",
    "F_LABEL_TIMEFRAME_SECONDS = 900\n",
    "\n",
    "TF_ARRAY = np.array(['H1', 'H4', 'D1', 'M15', 'M5'])\n",
    "\n",
    "tfs = TF_ARRAY[TF_ARRAY != F_LABEL_TIMEFRAME]\n",
    "\n",
    "_mof = []\n",
    "\n",
    "if F_SINGLE_MEDIUM:\n",
    "    _mof.append('m')\n",
    "else:\n",
    "    _mof.append('s')\n",
    "\n",
    "_mof.append(str(DAY_HISTORY_TO_PROCESS))\n",
    "\n",
    "if F_VOLUME:\n",
    "    _mof.append('v1')\n",
    "else:\n",
    "    _mof.append('v0')\n",
    "\n",
    "_mof.append('r' + str(F_REPEAT))\n",
    "\n",
    "if F_TIME:\n",
    "    _mof.append('t1')\n",
    "else:\n",
    "    _mof.append('t0')\n",
    "\n",
    "\n",
    "MODELS_FOLDER = 'C:/Projects/quantsmono/Python/etfc/models/' + '_'.join(_mof) + '-' + F_LABEL_TIMEFRAME + '_' + str(F_LABEL_PERIOD) + '/'\n",
    "\n",
    "models = [tf.keras.models.load_model(MODELS_FOLDER + 'model_0'),\n",
    "          tf.keras.models.load_model(MODELS_FOLDER + 'model_1'),\n",
    "          tf.keras.models.load_model(MODELS_FOLDER + 'model_2'),\n",
    "          tf.keras.models.load_model(MODELS_FOLDER + 'model_3'),\n",
    "          tf.keras.models.load_model(MODELS_FOLDER + 'model_4'),\n",
    "          tf.keras.models.load_model(MODELS_FOLDER + 'model_5'),\n",
    "          tf.keras.models.load_model(MODELS_FOLDER + 'model_6'),\n",
    "          tf.keras.models.load_model(MODELS_FOLDER + 'model_7'),\n",
    "          tf.keras.models.load_model(MODELS_FOLDER + 'model_8'),\n",
    "          tf.keras.models.load_model(MODELS_FOLDER + 'model_9'),\n",
    "          tf.keras.models.load_model(MODELS_FOLDER + 'model_10'),\n",
    "          tf.keras.models.load_model(MODELS_FOLDER + 'model_11'),\n",
    "          tf.keras.models.load_model(MODELS_FOLDER + 'model_12'),\n",
    "          tf.keras.models.load_model(MODELS_FOLDER + 'model_13')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def self_diff(a: np.ndarray, shift=1):\n",
    "    return a - np.roll(a, -shift)\n",
    "\n",
    "def build_features_one_timeframe(raw_data, timeframe):\n",
    "    # raw_data: old -> new\n",
    "    d = np.flipud(raw_data)\n",
    "    # d: new -> old\n",
    "    ts = [datetime.fromtimestamp(x) for x in d[:, 5]]\n",
    "    tt = [t.timetuple() for t in ts]\n",
    "    a = np.array([\n",
    "        d[:, 0],\n",
    "        d[:, 1],\n",
    "        d[:, 2],\n",
    "        d[:, 3],\n",
    "        np.maximum(d[:, 0], d[:, 3]),\n",
    "        np.minimum(d[:, 0], d[:, 3]),\n",
    "    ], dtype=float)\n",
    "    if F_SINGLE_MEDIUM:\n",
    "        a = np.vstack((\n",
    "            a,\n",
    "            d[:, 3] - d[:, 0],\n",
    "            d[:, 1] - d[:, 2],\n",
    "            d[:, 1] - d[:, 0],\n",
    "            d[:, 1] - d[:, 3],\n",
    "            d[:, 3] - d[:, 2],\n",
    "            d[:, 0] - d[:, 2]\n",
    "        ))\n",
    "        a = np.vstack((\n",
    "            a,\n",
    "            d[:, 1] - a[4],\n",
    "            d[:, 1] - a[5],\n",
    "            a[4] - d[:, 2],\n",
    "            a[5] - d[:, 2],\n",
    "            d[:, 3] + d[:, 0],\n",
    "            d[:, 1] + d[:, 2],\n",
    "            d[:, 1] + d[:, 0],\n",
    "            d[:, 1] + d[:, 3],\n",
    "            d[:, 0] + d[:, 2],\n",
    "            d[:, 3] + d[:, 2],\n",
    "            d[:, 1] + a[4],\n",
    "            d[:, 1] + a[5],\n",
    "            a[4] + d[:, 2],\n",
    "            a[5] + d[:, 2],\n",
    "        ))\n",
    "    if F_VOLUME:\n",
    "        a = np.vstack((a, d[:,4]))\n",
    "    f_h_single = a.shape[0]\n",
    "    for i in range(F_REPEAT):\n",
    "        a = np.vstack((a, self_diff(a[i*f_h_single : (i+1)*f_h_single])))\n",
    "    if F_TIME:\n",
    "        a = np.vstack((\n",
    "            a,\n",
    "            self_diff(d[:, 5]),\n",
    "            (np.sin(d[:, 5] * DAY) + 1) / 2,\n",
    "            (np.cos(d[:, 5] * DAY) + 1) / 2,\n",
    "            (np.sin(d[:, 5] * WEEK) + 1) / 2,\n",
    "            (np.cos(d[:, 5] * WEEK) + 1) / 2,\n",
    "            (np.sin(d[:, 5] * YEAR) + 1) / 2,\n",
    "            (np.cos(d[:, 5] * YEAR) + 1) / 2,\n",
    "            np.array([t.tm_yday for t in tt]) / 365,\n",
    "            np.array([t.tm_mday for t in tt]) / 30,\n",
    "            # np.array([calendar.monthrange(t.tm_year, t.tm_mon)[1] for t in tt]) / 30 - a[111], // TODO: Fix this shit\n",
    "            np.array([t.tm_wday for t in tt]) / 6,\n",
    "            np.array([t.tm_hour for t in tt]) / 23,\n",
    "            np.array([t.tm_min for t in tt]) / 59,\n",
    "        ))\n",
    "\n",
    "    return a\n",
    "\n",
    "\n",
    "def build_image(a, w):\n",
    "    return [np.interp(x, (x.min(), x.max()), (0, 1)) for x in a[:,:w]]\n",
    "\n",
    "#     M15    H1     H4     M5     D1\n",
    "# ----50-----50-----20-----20-----10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def con_predict(raw_data_m5, raw_data_m15, raw_data_h1, raw_data_h4, raw_data_d1):\n",
    "    features_m5 = build_features_one_timeframe(raw_data_m5, 'M5')\n",
    "    features_m15 = build_features_one_timeframe(raw_data_m15, 'M15')\n",
    "    features_h1 = build_features_one_timeframe(raw_data_h1, 'H1')\n",
    "    features_h4 = build_features_one_timeframe(raw_data_h4, 'H4')\n",
    "    features_d1 = build_features_one_timeframe(raw_data_d1, 'D1')\n",
    "\n",
    "    ims = {\n",
    "        'M5': build_image(features_m5, IMAGE_LENGTH_M5),\n",
    "        'M15': build_image(features_m15, IMAGE_LENGTH_M15),\n",
    "        'H1': build_image(features_h1, IMAGE_LENGTH_H1),\n",
    "        'H4': build_image(features_h4, IMAGE_LENGTH_H4),\n",
    "        'D1': build_image(features_d1, IMAGE_LENGTH_D1)\n",
    "    }\n",
    "\n",
    "    \n",
    "    test_image = np.hstack((\n",
    "        ims.get(F_LABEL_TIMEFRAME),\n",
    "        ims.get(tfs[0]),\n",
    "        ims.get(tfs[1]),\n",
    "        ims.get(tfs[2]),\n",
    "        ims.get(tfs[3])\n",
    "    ))\n",
    "\n",
    "    b_test_im = tf.constant([test_image])\n",
    "    preds = np.array([np.argmax(models[0].predict(b_test_im), axis=-1),\n",
    "                        np.argmax(models[1].predict(b_test_im), axis=-1),\n",
    "                        np.argmax(models[2].predict(b_test_im), axis=-1),\n",
    "                        np.argmax(models[3].predict(b_test_im), axis=-1),\n",
    "                        np.argmax(models[4].predict(b_test_im), axis=-1),\n",
    "                        np.argmax(models[5].predict(b_test_im), axis=-1),\n",
    "                        np.argmax(models[6].predict(b_test_im), axis=-1),\n",
    "                        np.argmax(models[7].predict(b_test_im), axis=-1),\n",
    "                        np.argmax(models[8].predict(b_test_im), axis=-1),\n",
    "                        np.argmax(models[9].predict(b_test_im), axis=-1),\n",
    "                        np.argmax(models[10].predict(b_test_im), axis=-1),\n",
    "                        np.argmax(models[11].predict(b_test_im), axis=-1),\n",
    "                        np.argmax(models[12].predict(b_test_im), axis=-1),\n",
    "                        np.argmax(models[13].predict(b_test_im), axis=-1)])\n",
    "\n",
    "\n",
    "    pred_buy = preds.flat[7:].sum()\n",
    "    pred_sell = preds.flat[:7].sum()\n",
    "\n",
    "    buy_condition = (pred_buy > pred_sell + THRESOLD_DIFF) & (pred_buy >= TARGET)\n",
    "\n",
    "    if (buy_condition):\n",
    "        return 1, str(raw_data_m5[-1][5]) + \" \" + str(raw_data_m15[-1][5]) + \" \" + str(raw_data_h1[-1][5]) \n",
    "        # return 1, str(datetime.fromtimestamp(raw_data_m5[-1][5])) + \" \" + str(datetime.fromtimestamp(raw_data_m15[-1][5]))\n",
    "\n",
    "    # return 0, str(datetime.fromtimestamp(raw_data_m5[-1][5])) + \" \" + str(datetime.fromtimestamp(raw_data_m15[-1][5]))\n",
    "    return 0, str(raw_data_m5[-1][5]) + \" \" + str(raw_data_m15[-1][5]) + \" \" + str(raw_data_h1[-1][5])  + \" \" + str(raw_data_h4[-1][5])  + \" \" + str(raw_data_d1[-1][5]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import MetaTrader5 as mt5\n",
    "\n",
    "\n",
    "IMAGE_LENGTH_M15 = 24\n",
    "IMAGE_LENGTH_H1 = 24\n",
    "IMAGE_LENGTH_H4 = 12\n",
    "IMAGE_LENGTH_M5 = 12\n",
    "IMAGE_LENGTH_D1 = 10\n",
    "\n",
    "\n",
    "mt5.initialize()\n",
    "\n",
    "raw_data_m5 = mt5.copy_rates_from(INPUT_SYMBOL, mt5.TIMEFRAME_M5, datetime(2020, 7, 27, 22,55), IMAGE_LENGTH_M5 + 5)\n",
    "raw_data_m15 = mt5.copy_rates_from(INPUT_SYMBOL, mt5.TIMEFRAME_M15, datetime(2020, 7, 27, 22,45), IMAGE_LENGTH_M15 + 5)\n",
    "raw_data_h1 = mt5.copy_rates_from(INPUT_SYMBOL, mt5.TIMEFRAME_H1, datetime(2020, 7, 27, 22,0), IMAGE_LENGTH_H1 + 5)\n",
    "raw_data_h4 = mt5.copy_rates_from(INPUT_SYMBOL, mt5.TIMEFRAME_H4, datetime(2020, 7, 27, 19,0), IMAGE_LENGTH_H4 + 5)\n",
    "raw_data_d1 = mt5.copy_rates_from(INPUT_SYMBOL, mt5.TIMEFRAME_D1, datetime(2020, 7, 26, 23,0), IMAGE_LENGTH_D1 + 5)\n",
    "\n",
    "mt5.shutdown()\n",
    "\n",
    "\n",
    "def blah(x):\n",
    "    rr = np.zeros(shape=(len(x), 6), dtype=float)\n",
    "    rr[:,0] = x['open']\n",
    "    rr[:,1] = x['high']\n",
    "    rr[:,2] = x['low']\n",
    "    rr[:,3] = x['close']\n",
    "    rr[:,4] = x['tick_volume']\n",
    "    rr[:,5] = x['time']\n",
    "    return rr\n",
    "    \n",
    "r_m15 = blah(raw_data_m15)\n",
    "r_m5 = blah(raw_data_m5)\n",
    "r_h1 = blah(raw_data_h1)\n",
    "r_h4 = blah(raw_data_h4)\n",
    "r_d1 = blah(raw_data_d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0, '1595861700.0 1595861100.0 1595858400.0 1595836800.0 1595548800.0')"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "con_predict(r_m5,r_m15,r_h1,r_h4,r_d1)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m56"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}